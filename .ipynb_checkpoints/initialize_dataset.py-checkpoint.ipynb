{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "import numpy as np\n",
    "from random import uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from img_helper import rgb2hsv_set, illuminate_images, add_noise\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "dataset_path = \"ExDark/\"\n",
    "dataset_npy_path = \"Dataset npys/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "img_width = 100\n",
    "img_height = img_width\n",
    "img_channels = 3\n",
    "\n",
    "# Load in all images from the specified folder\n",
    "def create_datasets(img_folder, tt_split, vt_split):\n",
    "\n",
    "    img_files=[]\n",
    "    for (dir_path, dir_names, file_names) in walk(img_folder):\n",
    "        for fn in file_names:\n",
    "            if fn is not \".ipynb_checkpoints\":\n",
    "                img_files.append(os.path.join(dir_path,fn))\n",
    "    \n",
    "    img_array = np.ndarray(shape=(len(img_files), img_width, img_height, img_channels),\n",
    "                         dtype=np.float32)\n",
    "\n",
    "    i = 0\n",
    "    for _file in img_files:\n",
    "    \t#img_path = img_folder + \"/\" + _file\n",
    "    \timg = load_img(_file, target_size=(img_width, img_height))\n",
    "    \tx = img_to_array(img)\n",
    "    \timg_array[i] = x\n",
    "    \ti += 1\n",
    "    \n",
    "    # Rescale the pixel values to range [0,1]\n",
    "    img_array = img_array/np.max(img_array)\n",
    "\n",
    "    # Split dataset into: 99% training and 1% test\n",
    "    train,test = train_test_split(img_array, test_size=tt_split, random_state=13)\n",
    "\n",
    "    # Split training set into: 80% training and 20% validation\n",
    "    train,valid = train_test_split(train, test_size=vt_split, random_state=13)\n",
    "\n",
    "    return train,test,valid\n",
    "\n",
    "# Create image datasets\n",
    "train_RGB_X,test_RGB_X,valid_RGB_X = create_datasets(dataset_path, 0.01, 0.2)\n",
    "\n",
    "np.save(os.path.join(dataset_npy_path,\"train_RGB_X.npy\"),train_RGB_X)\n",
    "np.save(os.path.join(dataset_npy_path,\"test_RGB_X.npy\"),test_RGB_X)\n",
    "np.save(os.path.join(dataset_npy_path,\"valid_RGB_X.npy\"),valid_RGB_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify datasets for networks\n",
    "train_HSV_X = rgb2hsv_set(train_RGB_X)\n",
    "valid_HSV_X = rgb2hsv_set(valid_RGB_X)\n",
    "\n",
    "train_HSV_Y = illuminate_images(train_HSV_X)\n",
    "valid_HSV_Y = illuminate_images(valid_HSV_X)\n",
    "\n",
    "train_noisy_HSV_Y = add_noise(train_HSV_Y)\n",
    "valid_noisy_HSV_Y = add_noise(valid_HSV_Y)\n",
    "\n",
    "test_HSV_X = rgb2hsv_set(test_RGB_X)\n",
    "\n",
    "np.save(os.path.join(dataset_npy_path,\"train_HSV_X.npy\"),train_HSV_X)\n",
    "np.save(os.path.join(dataset_npy_path,\"valid_HSV_X.npy\"),valid_HSV_X)\n",
    "\n",
    "np.save(os.path.join(dataset_npy_path,\"train_HSV_Y.npy\"),train_HSV_Y)\n",
    "np.save(os.path.join(dataset_npy_path,\"valid_HSV_Y.npy\"),valid_HSV_Y)\n",
    "\n",
    "np.save(os.path.join(dataset_npy_path,\"train_noisy_HSV_Y.npy\"),train_noisy_HSV_Y)\n",
    "np.save(os.path.join(dataset_npy_path,\"valid_noisy_HSV_Y.npy\"),valid_noisy_HSV_Y)\n",
    "\n",
    "np.save(os.path.join(dataset_npy_path,\"test_HSV_X.npy\"),test_HSV_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
